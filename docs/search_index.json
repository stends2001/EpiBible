[["index.html", "Epibible Chapter 1 Preface", " Epibible Sten de Schrijver 2025-07-21 Chapter 1 Preface Hi, and welcome! This digital book is meant to serve as a big piece of reference material, covering everything someone with a basic understanding of epidemiology should know. We will be covering some fundamental epidemiology itself, and we will also integrate this fundamental knowledge into learning how to use R for collecting, processing, visualizing and analyzing the most important thing in epidemiology; data. The idea behind this material is not to make an R-wizard out of you. The goal is to get you familiar with R, and with other tools and sources, so that you can develop your own toolkit by yourself, after finishing this document! You will get familiar with some basic computations in R, with some actual mathematical modelling, and with Github and other programming - words that any epidemiologist should be familiar with. "],["overview.html", "Chapter 2 Overview", " Chapter 2 Overview "],["introduction-to-epidemiology.html", "Chapter 3 Introduction to Epidemiology", " Chapter 3 Introduction to Epidemiology "],["modelling.html", "Chapter 4 Modelling 4.1 Compartmental models 4.2 Forecasting", " Chapter 4 Modelling 4.1 Compartmental models 4.2 Forecasting 4.3 The world of AI 4.1 Compartmental models 4.1.1 SIR model in theory Compartmental models divide a population into distinct groups, or compartments, each governed by specific rules that describe how individuals move between compartments over time. In epidemiology, one of the most common models is the SIR model, which divides the population into three compartments: Susceptible (S): individuals who can contract the disease Infectious (I): individuals who are currently infected and can transmit the disease Recovered (R): individuals who have recovered and are no longer infectious Individuals move from S to I (when infected), and from I to R (when they recover). This progression can be described using either discrete-time or continuous-time equations. 4.1.1.1 Discrete-Time Formulation The discrete-time version of the SIR model is expressed as: \\[ \\begin{aligned} S_{t+1} &amp;= S_t - \\beta S_t I_t \\\\ I_{t+1} &amp;= I_t + \\beta S_t I_t - \\gamma I_t \\\\ R_{t+1} &amp;= R_t + \\gamma I_t \\end{aligned} \\] Here, \\(S_{t+1}\\) is the number of susceptible individuals at the next time step, determined by subtracting those who become infected. \\(I_{t+1}\\) increases with new infections and decreases as people recover. \\(R_{t+1}\\) increases with recoveries. 4.1.1.2 Continuous-Time Formulation (ODEs) For more refined, continuous-time modeling, we use ordinary differential equations: \\[ \\begin{aligned} \\frac{dS}{dt} &amp;= -\\beta S I \\\\ \\frac{dI}{dt} &amp;= \\beta S I - \\gamma I \\\\ \\frac{dR}{dt} &amp;= \\gamma I \\end{aligned} \\] These represent the rate of change of each compartment over time. Where: - \\(\\beta\\) is the transmission rate - \\(\\gamma\\) is the recovery rate - \\(N = S + I + R\\) is the total population 4.1.2 2.1.2 SIR model in R Despite its simplicity, the SIR model can be surprisingly effective. During the COVID-19 pandemic, many government advisors based their projections on variations of this basic framework. As an example, consider an influenza outbreak that occurred in 1978 at a boarding school in England. The on-site physician documented how many students were sick (in bed) and how many were recovering (convalescent) each day. This dataset is included in the outbreaks R package, allowing us to study it directly. library(outbreaks) data(&quot;influenza_england_1978_school&quot;) outbreak_data &lt;- influenza_england_1978_school head(outbreak_data) ## date in_bed convalescent ## 1 1978-01-22 3 0 ## 2 1978-01-23 8 0 ## 3 1978-01-24 26 0 ## 4 1978-01-25 76 0 ## 5 1978-01-26 225 9 ## 6 1978-01-27 298 17 outbreak_data_long &lt;- pivot_longer(outbreak_data, cols = c(in_bed, convalescent), names_to = &quot;group&quot;, values_to = &quot;count&quot;) ggplot(outbreak_data_long, aes(x = date, y = count, color = group)) + geom_line(linewidth = 1.2) + geom_point(color = &quot;black&quot;, size = 2) + scale_x_date(breaks = outbreak_data_long$date, date_labels = &quot;%b %d&quot;) + labs(title = &quot;Influenza Outbreak (1978 Boarding School)&quot;, x = &quot;&quot;, y = &quot;Number of Students&quot;, color = &quot;Status&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Now let’s implement the SIR model in R: sir_model &lt;- function(number_of_days, BETA, GAMMA, dt = 1) { N &lt;- 763 I0 &lt;- 1 S0 &lt;- N - I0 R0 &lt;- 0 times &lt;- seq(0, number_of_days, by = dt) n_steps &lt;- length(times) sirdata &lt;- data.frame( t = times, S = numeric(n_steps), I = numeric(n_steps), R = numeric(n_steps) ) sirdata[1, ] &lt;- c(0, S0, I0, R0) for (tt in 2:n_steps) { S_prev &lt;- sirdata$S[tt - 1] I_prev &lt;- sirdata$I[tt - 1] R_prev &lt;- sirdata$R[tt - 1] new_infections &lt;- BETA * S_prev * I_prev * dt new_recoveries &lt;- GAMMA * I_prev * dt new_infections &lt;- min(new_infections, S_prev) new_recoveries &lt;- min(new_recoveries, I_prev) S_new &lt;- S_prev - new_infections I_new &lt;- I_prev + new_infections - new_recoveries R_new &lt;- R_prev + new_recoveries sirdata[tt, ] &lt;- c(times[tt], S_new, I_new, R_new) } return(sirdata) } output = sir_model(14, 0.0026, 0.565, 0.1) sirdata_long = pivot_longer(output, cols = c(&quot;S&quot;, &quot;I&quot;, &quot;R&quot;), names_to = &quot;compartment&quot;, values_to = &quot;count&quot;) ggplot(sirdata_long, aes(x = t, y = count, color = compartment)) + geom_line(linewidth = 1.2) + labs(title = &quot;Influenza Outbreak (1978 Boarding School)&quot;, x = &quot;&quot;, y = &quot;Number of Students&quot;, color = &quot;Status&quot;) + theme_minimal() Let’s now compare the observed in_bed data with the simulated number of infectious individuals: sir_output &lt;- sir_model(14, 0.0026, 0.565, dt = 0.1) sir_daily &lt;- sir_output %&gt;% group_by(day = floor(t)) %&gt;% summarize(I_simulated = mean(I)) observed_data &lt;- outbreak_data %&gt;% mutate(day = as.numeric(date - min(date))) %&gt;% select(day, in_bed) plot_data &lt;- left_join(observed_data, sir_daily, by = &quot;day&quot;) %&gt;% pivot_longer(cols = c(in_bed, I_simulated), names_to = &quot;type&quot;, values_to = &quot;count&quot;) ggplot(plot_data, aes(x = day, y = count, color = type)) + geom_line(linewidth = 1.2) + geom_point(size = 2, alpha = 0.8) + scale_x_continuous(breaks = 0:max(plot_data$day)) + labs(title = &quot;Observed vs Simulated Infections&quot;, x = &quot;Days Since Outbreak Start&quot;, y = &quot;Number of Students&quot;, color = &quot;Data Type&quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 0)) 4.2 Forecasting Forecasting plays a crucial role in infectious disease epidemiology by enabling short-term projections of case counts. These projections help guide timely public health decisions, especially when diseases exhibit seasonal or trend-driven behavior. In this section, we compare two popular time series approaches: Holt-Winters exponential smoothing, which models level, trend, and seasonality using exponentially weighted averages. ARIMA (AutoRegressive Integrated Moving Average), a flexible class of models that can account for autoregressive lags, differencing (trends), and moving average components, including seasonal extensions (SARIMA). Unlike mechanistic models (e.g., SIR), these statistical methods do not rely on assumptions about transmission mechanisms. Instead, they learn from the patterns and structure of historical data to forecast future values. We apply both models to weekly national tick-borne encephalitis (TBE) cases and generate forecasts for the year following a specified historical cutoff. library(dplyr) library(ggplot2) library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo library(lubridate) library(patchwork) # --- Load and preprocess data --- tbe_local &lt;- read.csv(&quot;C:/Users/stend/Documents/2. Extracurricular/EpiBible/tick_borne_encephalitis.csv&quot;) tbe_national &lt;- tbe_local %&gt;% mutate(timestamp = as.Date(timestamp)) %&gt;% group_by(timestamp) %&gt;% summarise(cases = sum(cases), .groups = &quot;drop&quot;) # --- Forecasting setup --- year &lt;- 2018 # Change to define cutoff year tbe_national_context &lt;- tbe_national %&gt;% filter(year(timestamp) &lt;= year) tbe_national_future &lt;- tbe_national %&gt;% filter(year(timestamp) == year + 1) %&gt;% arrange(timestamp) # ---- Create time series object ---- context_ts &lt;- ts(tbe_national_context$cases, frequency = 52) # ---- Holt-Winters model ---- hw_model &lt;- HoltWinters(context_ts) forecast_hw &lt;- forecast(hw_model, h = 52) predicted_df_hw &lt;- data.frame( timestamp = seq.Date(from = as.Date(paste0(year + 1, &quot;-01-01&quot;)), by = &quot;week&quot;, length.out = 52), cases = as.numeric(forecast_hw$mean), type = &quot;predicted_hw&quot; ) # ---- ARIMA model ---- arima_model &lt;- auto.arima(context_ts, seasonal = TRUE) forecast_arima &lt;- forecast(arima_model, h = 52) predicted_df_arima &lt;- data.frame( timestamp = seq.Date(from = as.Date(paste0(year + 1, &quot;-01-01&quot;)), by = &quot;week&quot;, length.out = 52), cases = as.numeric(forecast_arima$mean), type = &quot;predicted_arima&quot; ) # ---- Combine all data for plotting ---- context_labeled &lt;- tbe_national_context %&gt;% mutate(type = &quot;historical&quot;) future_labeled &lt;- tbe_national_future %&gt;% mutate(type = &quot;observed&quot;) combined_data &lt;- bind_rows(context_labeled, future_labeled, predicted_df_hw, predicted_df_arima) # ---- Plot full timeline ---- main_plot &lt;- ggplot(combined_data, aes(x = timestamp, y = cases, color = type)) + geom_line(linewidth = 1.2) + scale_color_manual(values = c( &quot;historical&quot; = &quot;#1f77b4&quot;, &quot;observed&quot; = &quot;#2ca02c&quot;, &quot;predicted_hw&quot; = &quot;#d62728&quot;, &quot;predicted_arima&quot; = &quot;#ff7f0e&quot; )) + theme_classic() + labs( title = paste(&quot;TBE Weekly Cases: Forecasting&quot;, year + 1), x = &quot;Time&quot;, y = &quot;Cases&quot;, color = &quot;Data Type&quot; ) + theme( legend.position = &quot;top&quot;, plot.title = element_text(face = &quot;bold&quot;, size = 16) ) # ---- Plot zoomed forecast year ---- zoom_plot &lt;- combined_data %&gt;% filter(year(timestamp) == year + 1) %&gt;% ggplot(aes(x = timestamp, y = cases, color = type)) + geom_line(linewidth = 1.2) + scale_color_manual(values = c( &quot;historical&quot; = &quot;#1f77b4&quot;, &quot;observed&quot; = &quot;#2ca02c&quot;, &quot;predicted_hw&quot; = &quot;#d62728&quot;, &quot;predicted_arima&quot; = &quot;#ff7f0e&quot; )) + theme_classic() + labs( title = paste(&quot;Zoom: Forecasts vs Observed in&quot;, year + 1), x = &quot;Week&quot;, y = &quot;Cases&quot; ) + theme( legend.position = &quot;none&quot;, plot.title = element_text(face = &quot;bold&quot;) ) # ---- Combine and show ---- main_plot / zoom_plot + plot_layout(heights = c(2, 1)) This analysis demonstrates how different statistical forecasting methods—Holt-Winters vs ARIMA—perform on the same epidemiological time series. While Holt-Winters is intuitive and captures seasonality well, ARIMA can offer greater flexibility in modeling autocorrelated structures. Comparing their predictions side-by-side allows us to evaluate model fit and choose an approach best suited for early warning or planning systems. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
